1. NLP Basics

    NLP = Natural Language Processing
    field concerned w the ability of a computer to understand, analyze, manipulate, and potentially generate human language.

    examples
    - spam filtering
    - auto-correct
    - auto-complete

    Natural Language Toolkit

    findall() - finds the words/characters and returns those
    split() - splits the string by specific characters and returns the splitted strings

    REGEX
        - \W and \w (word)
        - \S and \s (space)
        capital refers to non-[character] such as \W refers to non-word

    Raw test - model can't distinguish words
    Tokenize - tell the model what to look at
    Clean text - remove stop words/ punctuation, stemming, etc.
    Vectorize - convert to numeric format
    Machine Learning Algorithm - fit/train model
    Spam Filter - system to filter emails

    Quiz:

    1) Which choice is an example of unstructured data?
        > a PDF document
          - A PDF document usually contains free flowing text with no defined patterns for punctuation and formatting.
    2) When using pd.read_csv(), how can you tell it that you are using tabs as separators and there are no headers?
        > sep="\t", header=None
    3) What is the length of the list returned by the following split call: re.split('\s',"This is an interesting te+st")
        > 5
    4) What is the core component of natural language processing?
        > extracting information from human language
    5) What built-in Python function can be used to help remove special characters from a text file?
        > string.punctuation
    6) When would you use the + sign in a regular expression?
        > when you need to return more than one character at a time
    7) How would you describe the concept of stemming?
        > Though they may have different affixes, words that share the same stem have similar semantic meaning. Stemming is able to determine that 'learned' and 'learning' , though they have different affixes, each contain the same root word 'learn'.
    8) Besides manual parsing, what is an alternative method to parse a tab-delimited text file?
        > Use the Pandas read csv function.
    9) In the machine learning pipeline, _____ is about converting to numeric form.
        > vectorizing
    10) Before you begin to create a replacement expression, what should be true about your findall expression?
        > It is able to capture the correct sequence and any misspellings.
    11) What should be your first step when trying to read an unstructured text file into your code?
        > Read the text file to see patterns and determine the next step.
    12) What is the result of the following call: re.findall('[A-Z]+', "I like this test")
        > ['I']
    13) What is an important consideration when testing regular expressions?
        > Make sure extra spaces and special characters are correctly handled.

Chapter 2

    Stemming -> two words that have some sort of relation
        ex) electricity and electrical -> electric (stem)
        - correlates words w similar meaning
        - reduces the corpus of words the model is exposed to
        panda's stem function
    Lemmatizing
        - process of grouping together the inflected forms of a word so they can be analyzed as a single term, identified by the word's lemma
        - similar to stemming. both condenses derived words into their base forms.
        NLTK's WordNetLemmatizer 

    Stemming might make a non-existent word and is less accurate.
    Lemmatizing is more accurate as it will always return a dictionary word, but it may be more computationally expensive

    Quiz:

    1) When might you use lemmatizing over stemming?
        > when accuracy is preferred more than speed. Lemmatizing uses a more sophisticated algorithm to find root words at the expense of speed.

Chapter 3

    Vectorzing -> process of encoding text as integers to create feature vectors.
    Feature vector -> An n-dimensional vector of numerical features that represent some object 
    - counts how many times a word appears in a model
    - raw text converted to numbers for python to understand such as
        - counting how many times a word appears in a text

    Sparse matrix, a matrix in which most entries are 0. In efficient storage, a sparse matrix will be stored by only storing the locations of non-zero elements.

    Quiz

    1) What does TF represent in the TF-IDF equation?
        > the number of times a particular word appears in a sentence divided by the total number of words in the sentence
    2) What will NOT change in a document term matrix when using different vectorizing methods?
        > The number of rows will not change. It will always indicate the number of documents/messages in the data.
    3) Which item is NOT found in a document term matrix?
        > punctuation

Chapter 4

    Feature Engineering -> creating new features or transforming your existing features get the most out of your data
    - features can be seen as things that we could use when it comes to classifying data such as which has capitalization.
    - power transformations are features that are square or squareroot, and so on
    - standardized data

    Quiz

    1) What feature can be used by a model to decipher spam from ham.
        - length of the text
        - percentage of characters that are capitalized
        - percentage of characters that are punctuations
    2) What result will you obtain from the histogram when you test "Create feature for text message length"?
        > spam messages tend to be longer than non-spam messages
    3) When creating a lambda expression, you need to count the characters and ignore white spaces. What expression that helps you accomplish the task.
        > len(x) - x.count(" ")

Chapter 5

    Machine Learning -> the field of study that gives computers to learn without being explicitly programmed

    Supervised Learning
        - inferring a function from labeled training data to make predictions on unseen data
        - ex) spam filter of emails
    Unsupervised Learning
        - Deriving structure from data where we dont know the effect of any of the variables
        - ex) based on content of email, group similar emails together in distinct folders

    Holdout Test Set
        - sample of data not used in fitting a model for the purpose of evaluating the model's ability to generalize unseen data

    K-Fold Cross-Validation
        - full data set divided into k-subsets and the holdout method is repeated k-times

    ex) Fivefold Cross-Validation
        - 1st iteration: 10,000 examples divided into five subsets (2000 examples each). first four subsets could be used as the training set, and last subset could be used as the test set  
        - 2nd iteration, the fourth subset could be the test subset, while the other subsets are training sets.
        - 3rd iteration, the third subset could be the test set, while the others are the training sets.
        - and so forth

        - outcome (performance) should increase after each iteration

        accuracy = # predicted correctly / total # observations

        precision = # predicted as spam that are actually spam / total # predicted as spam

        recall = # predicted as spam that are actually spam / total # that are actually spam

    Ensemble Method -> technique that creates multiple methods and combines them to produce better results of any of the single models individually
        - model + model + ... + model = metamodel -> prediction
        - random forest -> constructs a collection of decision trees and aggregates the predections of all trees to determine final prediction
            > uses "bagging" method: samples randomly
            > unweighted voting for final prediction
            > easier to tune, harder to overfit
        - gradient boosting -> an iterative approach that takes the mistakes of prior iterations to create a strong learner
            > uses "boosting" method: higher weight on mistakes of prior iterations
            > weighted voting for final prediction
            > harder to tune, easier to overfit, but it's a lot more powerful if tuned right

    Quiz

    1) benefits of ensemble methods:
        - can be used for classification
        - accepts various types of inputs
        - easily handles outliers
    2) Accuracy is defined as # predicted correctly / total # observations